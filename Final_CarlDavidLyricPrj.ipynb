{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hyeonwid/Lyric_DLProject/blob/main/Final_CarlDavidLyricPrj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aA0LzleWMus"
      },
      "outputs": [],
      "source": [
        "!pip3 install datasets\n",
        "!pip3 install transformers\n",
        "!pip3 install xformers\n",
        "!pip3 install --upgrade accelerate\n",
        "!pip3 install evaluate\n",
        "!pip3 install bert_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hprsIyablnqV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, TFGPT2LMHeadModel, AutoConfig, TextStreamer, TrainingArguments, pipeline, Trainer, DataCollatorForLanguageModeling, TextDataset, DataCollatorForLanguageModeling\n",
        "\n",
        "#, AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the fine-tuned model\n",
        "save_directory = \"drive/MyDrive/beatles_4epochs\"\n",
        "\n",
        "loaded_model = GPT2LMHeadModel.from_pretrained(save_directory)\n",
        "loaded_tokenizer = GPT2Tokenizer.from_pretrained(save_directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_EKArccTFEJ",
        "outputId": "4c6a604e-5cb5-49e7-c334-130239e09906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNqMUEl_6us6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "2b9b8d07-fbd8-4928-e72f-a10676a35b85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"hi\\nI'm not sure what to say, but I know that I'm in love with you\\nYou're the only one I've ever known\\nAnd I don't know what else I can say\\n\\n\\n'Cause I love you so much, I just can't wait to see what you do with me\\nBaby, what do you want me to do?\\nOh, baby, you're so beautiful, it's like you've never seen me before\\nIt's just a dream come true\\nBut I want you to be my lover\\n(Baby)\\nOoh, ooh-ooh!\\n\\nLook at me, look at you! (Oh) Oh, yeah, oh-oh\\nDon't touch me like that\\nJust like I said, 'cause I wanna be your best friend\\nAww, that's what I like about you, isn't it? (You know) (I wanna) be yours, too\\nIsn't that what we\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "seed_text = \"I can't believe\"\n",
        "input_ids = loaded_tokenizer.encode(seed_text, return_tensors='pt')\n",
        "output = loaded_model.generate(input_ids,\n",
        "               max_length = 200, # max words of generated text \n",
        "               num_beams = 5, # increases output likelihood, keeps num of word sequences and chooses the best at the end\n",
        "               no_repeat_ngram_size  = 2, # faults repetition of phrases, even if it would result in a better \"fluency score\"\n",
        "               early_stopping = True)\n",
        "prediction = loaded_tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiS2rpgHWXfk",
        "outputId": "36402f38-1146-44b9-9347-b2e6d85f7737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset parquet (/root/.cache/huggingface/datasets/koudeheld___parquet/koudeheld--beatles_lyrics-3aa16592c8727c3d/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
          ]
        }
      ],
      "source": [
        "# Load the lyrics dataset\n",
        "dataset = load_dataset(\"koudeheld/beatles_lyrics\", split='train')\n",
        "\n",
        "# Filter the dataset for lyrics by the specified artist\n",
        "artist_lyrics = dataset['lyrics']\n",
        "\n",
        "train_split = 0.8\n",
        "test_split = 0.1\n",
        "\n",
        "train_ind = int(train_split * (len(artist_lyrics)))\n",
        "test_ind = int((1 - test_split) * (len(artist_lyrics)))\n",
        "\n",
        "X_train = (artist_lyrics[:train_ind])\n",
        "# X_valid = (artist_lyrics[train_ind:test_ind])\n",
        "# X_test = (artist_lyrics[test_ind:])\n",
        "X_test = (artist_lyrics[train_ind:])\n",
        "\n",
        "\n",
        "artist_lyrics_text = \"\\n\".join(X_train)\n",
        "# valid_text = \"\\n\".join(X_valid)\n",
        "test_text = \"\\n\".join(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perplexity\n",
        "from tqdm import tqdm\n",
        "\n",
        "encodings = loaded_tokenizer(test_text, return_tensors=\"pt\")\n",
        "\n",
        "max_length = loaded_model.config.n_positions\n",
        "stride = 512\n",
        "seq_len = encodings.input_ids.size(1)\n",
        "\n",
        "nlls = []\n",
        "prev_end_loc = 0\n",
        "for begin_loc in tqdm(range(0, seq_len, stride)):\n",
        "    end_loc = min(begin_loc + max_length, seq_len)\n",
        "    trg_len = end_loc - prev_end_loc  # may be different from stride on last loop\n",
        "    input_ids = encodings.input_ids[:, begin_loc:end_loc]\n",
        "    target_ids = input_ids.clone()\n",
        "    target_ids[:, :-trg_len] = -100\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = loaded_model(input_ids, labels=target_ids)\n",
        "\n",
        "        # loss is calculated using CrossEntropyLoss which averages over valid labels\n",
        "        # N.B. the model only calculates loss over trg_len - 1 labels, because it internally shifts the labels\n",
        "        # to the left by 1.\n",
        "        neg_log_likelihood = outputs.loss\n",
        "\n",
        "    nlls.append(neg_log_likelihood)\n",
        "\n",
        "    prev_end_loc = end_loc\n",
        "    if end_loc == seq_len:\n",
        "        break\n",
        "\n",
        "ppl = torch.exp(torch.stack(nlls).mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG7aVbeBuq-X",
        "outputId": "5a2b185e-8184-4f11-99a5-3d489054c941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 24/26 [03:37<00:18,  9.06s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perplexity\n",
        "ppl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJeSSQgbztl9",
        "outputId": "4f0826c4-ba6f-4bef-eacf-3684d62d9402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.3419)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPTZ0y8xQVEs"
      },
      "outputs": [],
      "source": [
        "# Load the GPT-2 model and tokenizer\n",
        "model_name = 'gpt2'\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name, pad_token_id=tokenizer.eos_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gD6ubPgDH44d"
      },
      "outputs": [],
      "source": [
        "dataset_files = \"beatles.txt\"\n",
        "\n",
        "dataset = TextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path=dataset_files,\n",
        "    block_size=128  # Adjust the block size according to your dataset\n",
        ")\n",
        "\n",
        "# Define the data collator for language modeling\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False  # Set mlm=True if your dataset contains masked language modeling\n",
        ")\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./author_model',\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=4,\n",
        "    save_total_limit=1,\n",
        ")\n",
        "\n",
        "# Define the Trainer and fine-tune the model\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "CnBMZOICJA4x",
        "outputId": "bc7d88ea-86ff-4da3-9354-4204f2130c17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='352' max='352' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [352/352 58:23, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=352, training_loss=2.116647893732244, metrics={'train_runtime': 3515.8374, 'train_samples_per_second': 0.4, 'train_steps_per_second': 0.1, 'total_flos': 91974795264000.0, 'train_loss': 2.116647893732244, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the fine-tuned model\n",
        "save_directory = \"beatles_4epochs\"\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iQa85B8SY2W",
        "outputId": "6a0d1f3b-c208-46ad-e447-23741d405e74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('beatles_4epochs/tokenizer_config.json',\n",
              " 'beatles_4epochs/special_tokens_map.json',\n",
              " 'beatles_4epochs/vocab.json',\n",
              " 'beatles_4epochs/merges.txt',\n",
              " 'beatles_4epochs/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "bertscore = load(\"bertscore\")\n",
        "\n",
        "X_test_prefix = []\n",
        "for elt in X_test:\n",
        "  X_test_prefix.append(\" \".join(elt.split(\" \")[:5]))\n",
        "\n",
        "predictions = []\n",
        "for phrase in X_test_prefix:\n",
        "  input_ids = tokenizer.encode(phrase, return_tensors='pt')\n",
        "  output = model.generate(input_ids,\n",
        "                max_length = 200, # max words of generated text \n",
        "                num_beams = 5, # increases output likelihood, keeps num of word sequences and chooses the best at the end\n",
        "                no_repeat_ngram_size  = 2, # faults repetition of phrases, even if it would result in a better \"fluency score\"\n",
        "                early_stopping = True)\n",
        "  predictions.append(tokenizer.decode(output[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "063ed60812a548cea780a6ff6276ec05",
            "b826651871ef444ab2f9e6389aca5bb4",
            "b4a1f0c47f524b10a347832554d24a8f",
            "f1a609e97d894de39cce0522e9bb3d71",
            "cb1d8e9a7ced41aaaf71e439608da8de",
            "6c262b01260a4f318bb68dc361f617d9",
            "d85c906b40374f90b12058921818e12b",
            "ecc0a8b82a3640dd962d48da4b930b5b",
            "47929fdcecc44a0c846c8508aedb1a77",
            "cff17fa11206461d917e5dead59350ff",
            "d1ebc78a77ce4df786d7970bdf71536e"
          ]
        },
        "id": "lG9zO3VAQEEK",
        "outputId": "7ec2801f-19e3-4276-b4bd-c6c3df3b7322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "063ed60812a548cea780a6ff6276ec05"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "references = X_test\n",
        "results = bertscore.compute(predictions=predictions, references=references, model_type=\"distilbert-base-uncased\", lang=\"en\")\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLrQqDJaZ4it",
        "outputId": "e4ffe053-9bfb-4f57-9f40-f3cec4d20865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'precision': [0.7445630431175232,\n",
              "  0.7875722646713257,\n",
              "  0.7535228133201599,\n",
              "  0.7277059555053711,\n",
              "  0.7496730089187622,\n",
              "  0.7919864654541016,\n",
              "  0.7590459585189819,\n",
              "  0.7841107249259949,\n",
              "  0.7349120378494263,\n",
              "  0.7645444869995117,\n",
              "  0.6321452856063843,\n",
              "  0.733690619468689,\n",
              "  0.735466718673706,\n",
              "  0.7399103045463562,\n",
              "  0.7122339606285095,\n",
              "  0.786553680896759,\n",
              "  0.7756639122962952,\n",
              "  0.758624255657196],\n",
              " 'recall': [0.8094819188117981,\n",
              "  0.788813591003418,\n",
              "  0.7799925804138184,\n",
              "  0.6938122510910034,\n",
              "  0.7487930655479431,\n",
              "  0.6576477885246277,\n",
              "  0.7643789052963257,\n",
              "  0.7110496759414673,\n",
              "  0.7383253574371338,\n",
              "  0.7851817011833191,\n",
              "  0.704975962638855,\n",
              "  0.7571793794631958,\n",
              "  0.7169095277786255,\n",
              "  0.7668697834014893,\n",
              "  0.6820694804191589,\n",
              "  0.6795876026153564,\n",
              "  0.759478747844696,\n",
              "  0.7889288663864136],\n",
              " 'f1': [0.7756664752960205,\n",
              "  0.7881924510002136,\n",
              "  0.7665292024612427,\n",
              "  0.7103551030158997,\n",
              "  0.7492327690124512,\n",
              "  0.7185924649238586,\n",
              "  0.7617030739784241,\n",
              "  0.7457951307296753,\n",
              "  0.7366147637367249,\n",
              "  0.774725615978241,\n",
              "  0.666577160358429,\n",
              "  0.7452499866485596,\n",
              "  0.7260695695877075,\n",
              "  0.7531488537788391,\n",
              "  0.6968254446983337,\n",
              "  0.7291686534881592,\n",
              "  0.7674859762191772,\n",
              "  0.7734798192977905],\n",
              " 'hashcode': 'distilbert-base-uncased_L5_no-idf_version=0.3.12(hug_trans=4.29.2)'}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ref = list(map(lambda x : x.split(), X_test))\n",
        "tests = list(map(lambda x : x.split(), predictions))\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "for i, test in enumerate(tests):\n",
        "  print('BLEU score for test' + str(i) + '-> {}'.format(sentence_bleu(ref, test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvr95Tc7cxz6",
        "outputId": "b41db3b7-4b39-4fe9-eb8f-c6f0dec3302a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score for test0-> 0.15483079870066502\n",
            "BLEU score for test1-> 0.16577377236021726\n",
            "BLEU score for test2-> 0.19632679614835538\n",
            "BLEU score for test3-> 0.0072751178566594415\n",
            "BLEU score for test4-> 0.2019281091276053\n",
            "BLEU score for test5-> 0.0028864882651961064\n",
            "BLEU score for test6-> 0.17779417167338324\n",
            "BLEU score for test7-> 0.024377529435777475\n",
            "BLEU score for test8-> 0.041610597986537406\n",
            "BLEU score for test9-> 0.15428552128294337\n",
            "BLEU score for test10-> 0.059025906675627834\n",
            "BLEU score for test11-> 0.11727621882505872\n",
            "BLEU score for test12-> 0.1461358125964144\n",
            "BLEU score for test13-> 0.15569020709095116\n",
            "BLEU score for test14-> 0.1879090832830776\n",
            "BLEU score for test15-> 0.030467653185229548\n",
            "BLEU score for test16-> 0.2083217673644468\n",
            "BLEU score for test17-> 0.18868166031774028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEWDopM6iRgi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18ec4b2e-3ee7-4b00-8fca-05e029ede198"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 0 sentiment: POSITIVE, Score: 0.9997898936271667\n",
            "Text 1 sentiment: NEGATIVE, Score: 0.9955527186393738\n",
            "Text 2 sentiment: POSITIVE, Score: 0.9975892305374146\n",
            "Text 3 sentiment: NEGATIVE, Score: 0.9896299242973328\n",
            "Text 4 sentiment: POSITIVE, Score: 0.9995619654655457\n",
            "Text 5 sentiment: POSITIVE, Score: 0.9441961646080017\n",
            "Text 6 sentiment: POSITIVE, Score: 0.9996829032897949\n",
            "Text 7 sentiment: POSITIVE, Score: 0.9959532022476196\n",
            "Text 8 sentiment: POSITIVE, Score: 0.9994283318519592\n",
            "Text 9 sentiment: POSITIVE, Score: 0.9997885823249817\n",
            "Text 10 sentiment: POSITIVE, Score: 0.9969080090522766\n",
            "Text 11 sentiment: POSITIVE, Score: 0.9998486042022705\n",
            "Text 12 sentiment: POSITIVE, Score: 0.9990554451942444\n",
            "Text 13 sentiment: POSITIVE, Score: 0.9929460883140564\n",
            "Text 14 sentiment: POSITIVE, Score: 0.9961601495742798\n",
            "Text 15 sentiment: POSITIVE, Score: 0.9978983402252197\n",
            "Text 16 sentiment: POSITIVE, Score: 0.9582606554031372\n",
            "Text 17 sentiment: POSITIVE, Score: 0.9990540146827698\n",
            "Text 0 sentiment: POSITIVE, Score: 0.9992407560348511\n",
            "Text 1 sentiment: NEGATIVE, Score: 0.9968400001525879\n",
            "Text 2 sentiment: POSITIVE, Score: 0.9980331063270569\n",
            "Text 3 sentiment: POSITIVE, Score: 0.9989064931869507\n",
            "Text 4 sentiment: NEGATIVE, Score: 0.9974276423454285\n",
            "Text 5 sentiment: POSITIVE, Score: 0.9933739900588989\n",
            "Text 6 sentiment: POSITIVE, Score: 0.9994162321090698\n",
            "Text 7 sentiment: POSITIVE, Score: 0.9995566010475159\n",
            "Text 8 sentiment: POSITIVE, Score: 0.9960694313049316\n",
            "Text 9 sentiment: POSITIVE, Score: 0.9991656541824341\n",
            "Text 10 sentiment: NEGATIVE, Score: 0.9995623230934143\n",
            "Text 11 sentiment: POSITIVE, Score: 0.9675746560096741\n",
            "Text 12 sentiment: POSITIVE, Score: 0.9707409143447876\n",
            "Text 13 sentiment: NEGATIVE, Score: 0.9993593096733093\n",
            "Text 14 sentiment: POSITIVE, Score: 0.997333288192749\n",
            "Text 15 sentiment: POSITIVE, Score: 0.9774238467216492\n",
            "Text 16 sentiment: NEGATIVE, Score: 0.9828648567199707\n",
            "Text 17 sentiment: POSITIVE, Score: 0.9979448914527893\n"
          ]
        }
      ],
      "source": [
        "sentiment_analysis = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "texts = []\n",
        "for prediction in predictions:\n",
        "  texts.append(prediction[:512])\n",
        "for lyrics in X_test:\n",
        "  texts.append(lyrics[:512])\n",
        "\n",
        "results = sentiment_analysis(texts)\n",
        "\n",
        "sentiments = []\n",
        "scores = []\n",
        "\n",
        "for result in results:\n",
        "  sentiments.append(result['label'])\n",
        "  scores.append(result['score'])\n",
        "\n",
        "for i in range(len(scores)):\n",
        "  print(f\"Text {i % 18} sentiment: {sentiments[i]}, Score: {scores[i]}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "063ed60812a548cea780a6ff6276ec05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b826651871ef444ab2f9e6389aca5bb4",
              "IPY_MODEL_b4a1f0c47f524b10a347832554d24a8f",
              "IPY_MODEL_f1a609e97d894de39cce0522e9bb3d71"
            ],
            "layout": "IPY_MODEL_cb1d8e9a7ced41aaaf71e439608da8de"
          }
        },
        "b826651871ef444ab2f9e6389aca5bb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c262b01260a4f318bb68dc361f617d9",
            "placeholder": "​",
            "style": "IPY_MODEL_d85c906b40374f90b12058921818e12b",
            "value": "Downloading builder script: 100%"
          }
        },
        "b4a1f0c47f524b10a347832554d24a8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecc0a8b82a3640dd962d48da4b930b5b",
            "max": 7950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47929fdcecc44a0c846c8508aedb1a77",
            "value": 7950
          }
        },
        "f1a609e97d894de39cce0522e9bb3d71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cff17fa11206461d917e5dead59350ff",
            "placeholder": "​",
            "style": "IPY_MODEL_d1ebc78a77ce4df786d7970bdf71536e",
            "value": " 7.95k/7.95k [00:00&lt;00:00, 194kB/s]"
          }
        },
        "cb1d8e9a7ced41aaaf71e439608da8de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c262b01260a4f318bb68dc361f617d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d85c906b40374f90b12058921818e12b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecc0a8b82a3640dd962d48da4b930b5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47929fdcecc44a0c846c8508aedb1a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cff17fa11206461d917e5dead59350ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1ebc78a77ce4df786d7970bdf71536e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}